name: Get VLille info every 10min by executing a Python Script and saving CSV

on:
  schedule:
    - cron: '*/10 * * * *'  # Every 10 min
  workflow_dispatch:

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout the repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'


      - name: Install Scraper Dependencies
        run: |
          pip install uv
          cd scrape_data
          uv sync

      - name: Write GCP credentials to file
        run: |
          echo "${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}" > /tmp/account.json

      - name: Run Python script with uv
        env:
          GOOGLE_APPLICATION_CREDENTIALS: /tmp/account.json
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          BIGQUERY_DATASET_ID: ${{ secrets.BIGQUERY_DATASET_ID }}
          BIGQUERY_TABLE_ID: ${{ secrets.BIGQUERY_TABLE_ID }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd scrape_data
          uv run scrapper.py