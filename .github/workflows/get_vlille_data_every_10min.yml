name: Get VLille info every 10min by executing a Python Script and saving CSV

on:
  schedule:
    - cron: '*/10 * * * *'  # Every 10 min
  workflow_dispatch:

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout the repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Set up GCP credentials
        run: |
          echo "${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}" > $HOME/gcp-key.json
        env:
          GOOGLE_APPLICATION_CREDENTIALS: $HOME/gcp-key.json

      - name: Install Scraper Dependencies
        run: |
          pip install uv  # Installer uv
          cd scrape_data  # Se déplacer dans le dossier du scraper
          uv sync         # Installer les dépendances

      - name: Run Python script with uv
        env:
          GOOGLE_APPLICATION_CREDENTIALS: $HOME/gcp-key.json
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          BIGQUERY_DATASET_ID: ${{ secrets.BIGQUERY_DATASET_ID }}
          BIGQUERY_TABLE_ID: ${{ secrets.BIGQUERY_TABLE_ID }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd scrape_data
          uv run scrapper.py
