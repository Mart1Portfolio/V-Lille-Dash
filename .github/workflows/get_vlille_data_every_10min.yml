name: Get VLille info every 10min by excecuting a Python Script and saving CSV

on:
  schedule:
    - cron: '*/10 * * * *'  # Every 10 min
  workflow_dispatch:  

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout the repository
        uses: actions/checkout@v4
        with : 
          fetch-depth: 1 #Permet d'éviter de récupérer tout l'historique 

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install Scraper Dependencies
        run: |
          pip install uv  # Installer uv via pip
          cd scrape_data  # 1. On se déplace dans le dossier du scraper
          uv sync         # 2. On installe ses dépendances (via uv.lock)
      - name: Run Python script with uv
        run: |
          cd scrape_data  # Se déplacer dans le dossier du scraper
          uv run scrapper.py  # Execute the script

      - name: Commit CSV to repository
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          
          git add scrape_data/data/vlille_data_*.csv
          
          git commit -m "Ajout de nouveaux fichiers CSV"

          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  
