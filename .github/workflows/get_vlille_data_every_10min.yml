name: Get VLille info every 10min by executing a Python Script and saving CSV

on:
  schedule:
    - cron: '*/10 * * * *'  # Every 10 min
  workflow_dispatch:

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout the repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Write GCP service account key
        run: |
          echo "${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}" > ./gcp-key.json
          echo "‚úÖ Fichier gcp-key.json cr√©√© √† $(pwd)"
          ls -l ./gcp-key.json  # V√©rification visuelle dans les logs
        shell: bash

      - name: Install Scraper Dependencies
        run: |
          pip install uv
          cd scrape_data
          uv sync

      - name: Run Python script with uv
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp-key.json
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          BIGQUERY_DATASET_ID: ${{ secrets.BIGQUERY_DATASET_ID }}
          BIGQUERY_TABLE_ID: ${{ secrets.BIGQUERY_TABLE_ID }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üîç V√©rification avant ex√©cution :"
          ls -l ${{ github.workspace }}/gcp-key.json || echo "‚ùå Cl√© non trouv√©e !"
          cd scrape_data
          uv run scrapper.py
