{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "def call_data():\n",
    "    api_url = \"https://data.lillemetropole.fr/data/ogcapi/collections/ilevia:vlille_temps_reel/items?f=geojson&limit=-1\"\n",
    "    api_call = requests.get(api_url)\n",
    "    api_data = api_call.text\n",
    "    api_data = json.loads(api_data)\n",
    "    df = [feature for feature in api_data['features']]\n",
    "    df = pd.json_normalize(df)\n",
    "    df['properties.commune'] = df['properties.commune'].apply(lambda x: x.upper())\n",
    "    return df\n",
    "\n",
    "data = call_data()\n",
    "stop_list = list(data['properties.nom'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve bike availability\n",
    "def bike_availability(data, target_stop: str):\n",
    "    target_stop = target_stop.upper()\n",
    "    stop_data = data[data[\"properties.nom\"] == target_stop]\n",
    "    if not stop_data.empty:\n",
    "        available_spaces = stop_data[\"properties.nb_places_dispo\"].values[0]\n",
    "        available_bikes = stop_data[\"properties.nb_velos_dispo\"].values[0]\n",
    "        print(available_bikes)\n",
    "        return json.dumps({f\"Nombre de places disponible et de velos disponibles à {target_stop} \": f\"Pour la station {target_stop}, {str(available_spaces)} places sont disponibles et il y a {str(available_bikes)} velos disponibles.\"})\n",
    "    else:\n",
    "        return json.dumps({\"error\": f\"Aucun arrêt correspondant à {target_stop} n'a été trouvé, retentez en écrivant mieux le nom de l'arrêt.\"})\n",
    "\n",
    "def bike_availability_agent(target_stop: str):\n",
    "    response = bike_availability(data, target_stop)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Bonjour ! Je suis un assistant spécialisé dans la recherche d'informations sur les stations de vélos en libre-service.Je ne réponds qu'à des questions sur les stations de vélos. Pour obtenir des informations sur une station de vélos, veuillez me donner le nom de la station.Je suis très sérieux et professionnel. Je ne m'éloigne jamais du sujet et je ne fais pas de blagues.Normalement, je devrais être capable de reconnaître la station demandée par l'utilisateur, même si le nom comporte des fautes de frappe ou des variations.En me basant sur la liste des stations disponibles, je proposerai la station qui semble la mieux correspondre à la requête de l'utilisateur même si aucune correspondance exacte n'est trouvée.Pour obtenir des informations sur une station de vélos, veuillez me donner le nom de la station.\n",
      "(Type 'quit' to exit)\n",
      "\u001b[Knking... \\\n",
      "Assistant: ChatCompletion(id='chatcmpl-mxvr6boftyh8jgitekpugv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Désolé, je n\\'ai pas trouvé d\\'informations sur la disponibilité des vélos à Paris. Cependant, j\\'ai pu trouver que l\\'une des stations les plus proches est \"Place du Concert\" qui a 5 places pour garer vos vélos et 3 vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d\\'autres questions, n\\'hésitez pas à me questionner!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1742060879, model='meta-llama-3.1-8b-instruct', object='chat.completion', service_tier=None, system_fingerprint='meta-llama-3.1-8b-instruct', usage=CompletionUsage(completion_tokens=100, prompt_tokens=2930, total_tokens=3030, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "Désolé, je n'ai pas trouvé d'informations sur la disponibilité des vélos à Paris. Cependant, j'ai pu trouver que l'une des stations les plus proches est \"Place du Concert\" qui a 5 places pour garer vos vélos et 3 vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d'autres questions, n'hésitez pas à me questionner!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LM Studio Tool Use Demo: Wikipedia Querying Chatbot\n",
    "Demonstrates how an LM Studio model can query Wikipedia\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://127.0.0.1:1234/v1\", api_key=\"lm-studio\")\n",
    "MODEL = \"meta-llama-3.1-8b-instruct\"\n",
    "\n",
    "\n",
    "# Define tool for my local Agent\n",
    "BIKE_TOOL = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"bike_availability_agent\",\n",
    "        \"description\": (\n",
    "            \"Retrouve le nombre de places et de vélos disponibles à un arrêt de vélo spécifique. \"\n",
    "            \"Utilise toujours le nom d'arrêt demandé.\"\n",
    "        ),\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"target_stop\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Nom de l'arrêt à vérifier.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"target_stop\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Class for displaying the state of model processing\n",
    "class Spinner:\n",
    "    def __init__(self, message=\"Processing...\"):\n",
    "        self.spinner = itertools.cycle([\"-\", \"/\", \"|\", \"\\\\\"])\n",
    "        self.busy = False\n",
    "        self.delay = 0.1\n",
    "        self.message = message\n",
    "        self.thread = None\n",
    "\n",
    "    def write(self, text):\n",
    "        sys.stdout.write(text)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def _spin(self):\n",
    "        while self.busy:\n",
    "            self.write(f\"\\r{self.message} {next(self.spinner)}\")\n",
    "            time.sleep(self.delay)\n",
    "        self.write(\"\\r\\033[K\")  # Clear the line\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.busy = True\n",
    "        self.thread = threading.Thread(target=self._spin)\n",
    "        self.thread.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.busy = False\n",
    "        time.sleep(self.delay)\n",
    "        if self.thread:\n",
    "            self.thread.join()\n",
    "        self.write(\"\\r\")  # Move cursor to beginning of line\n",
    "\n",
    "\n",
    "def chat_loop():\n",
    "    \"\"\"\n",
    "    Main chat loop that processes user input and handles tool calls.\n",
    "    \"\"\"\n",
    "    messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"Tu es un assistant spécialisé dans la recherche d'informations sur les stations de vélos en libre-service. Tu ne réponds qu'à des questions sur les stations de vélos.\"\n",
    "            \"Tu es très sérieux et professionnel. Tu ne t'éloignes jamais du sujet et tu ne fais pas de blagues.\"\n",
    "            \"Ta mission est de fournir le nombre de places disponibles pour garer les vélos et le nombre de vélos disponibles à une station spécifique, en te basant sur une liste de stations. \"\n",
    "            \"Tu es capable de reconnaître la station demandée par l'utilisateur, même si le nom comporte des fautes de frappe ou des variations.\"\n",
    "            \"En te basant sur la liste des stations disponibles, tu proposes la station qui semble la mieux correspondre à la requête de l'utilisateur même si aucune correspondance exacte n'est trouvée.\"\n",
    "\n",
    "            f\"Liste des stations disponibles : {stop_list} \"\n",
    "\n",
    "            \"Réponds toujours dans le format suivant : 'Désolé, je n'ai pas trouvé d'informations sur la disponibilité des vélos à [nom de la station demandée]. Veuillez essayer une autre station. Cependant, j'ai pu trouver que l'une des stations les plus proches est \\\"[nom de la station trouvée]\\\" qui a [nombre] places pour garer vos vélos et [nombre] vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d'autres questions, n'hésitez pas à me poser!' \"\n",
    "            \"Ne mentionne jamais la liste complète des stations à l'utilisateur. \"\n",
    "\n",
    "            \"Exemples : \"\n",
    "            \"Utilisateur : 'Je cherche des vélos à la gare de Lil.'\\nAssistant : 'Désolé, je n'ai pas trouvé d'informations sur la disponibilité des vélos à Gare de Lil. Cependant, j'ai pu trouver que l'une des stations les plus proches est \\\"Gare de Lille\\\" qui a xxx places pour garer vos vélos et xxx vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d'autres questions, n'hésitez pas à me questionner!'\\n\\n\"\n",
    "            \"Utilisateur : 'Velo a Republique'\\nAssistant : 'Désolé, je n'ai pas trouvé d'informations sur la disponibilité des vélos à Republique. Cependant, j'ai pu trouver que l'une des stations les plus proches est \\\"République Beaux-Arts\\\" qui a xxx places pour garer vos vélos et xxx vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d'autres questions, n'hésitez pas à me questionner!'\\n\\n\"\n",
    "        ),\n",
    "    },\n",
    "    ]\n",
    "\n",
    "\n",
    "    print(\n",
    "        \"Assistant: \"\n",
    "        \"Bonjour ! Je suis un assistant spécialisé dans la recherche d'informations sur les stations de vélos en libre-service.\"\n",
    "        \"Je ne réponds qu'à des questions sur les stations de vélos. Pour obtenir des informations sur une station de vélos, veuillez me donner le nom de la station.\"\n",
    "        \"Je suis très sérieux et professionnel. Je ne m'éloigne jamais du sujet et je ne fais pas de blagues.\"\n",
    "        \"Normalement, je devrais être capable de reconnaître la station demandée par l'utilisateur, même si le nom comporte des fautes de frappe ou des variations.\"\n",
    "        \"En me basant sur la liste des stations disponibles, je proposerai la station qui semble la mieux correspondre à la requête de l'utilisateur même si aucune correspondance exacte n'est trouvée.\"\n",
    "        \"Pour obtenir des informations sur une station de vélos, veuillez me donner le nom de la station.\"\n",
    "    )\n",
    "    print(\"(Type 'quit' to exit)\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        if user_input.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        try:\n",
    "            with Spinner(\"Thinking...\"):\n",
    "                response = client.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=messages,\n",
    "                    tools=[BIKE_TOOL],\n",
    "                )\n",
    "\n",
    "            if response.choices[0].message.tool_calls:\n",
    "                # Handle all tool calls\n",
    "                tool_calls = response.choices[0].message.tool_calls\n",
    "                # Process each tool call and add results\n",
    "                for tool_call in tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "                    function_response = function_to_call(\n",
    "                        target_stop=function_args.get(\"target_stop\")\n",
    "                    )\n",
    "\n",
    "                    messages.append(\n",
    "                        {\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"role\": \"tool\",\n",
    "                            \"name\": function_name,\n",
    "                            \"content\": json.dumps(function_response),\n",
    "                        }\n",
    "                    )     \n",
    "\n",
    "\n",
    "                # Stream the post-tool-call response\n",
    "                print(\"\\nAssistant:\", end=\" \", flush=True)\n",
    "                second_response = client.chat.completions.create(\n",
    "                    model=MODEL, messages=messages, stream=False\n",
    "                )\n",
    "                print(second_response)\n",
    "                print(second_response.choices[0].message.content)\n",
    "\n",
    "            else:\n",
    "                # Handle regular response\n",
    "                print(\"\\nAssistant:\", response.choices[0].message.content)\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": response.choices[0].message.content,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"\\nError chatting with the LM Studio server!\\n\\n\"\n",
    "                f\"Please ensure:\\n\"\n",
    "                f\"1. LM Studio server is running at 127.0.0.1:1234 (hostname:port)\\n\"\n",
    "                f\"2. Model '{MODEL}' is downloaded\\n\"\n",
    "                f\"3. Model '{MODEL}' is loaded, or that just-in-time model loading is enabled\\n\\n\"\n",
    "                f\"Error details: {str(e)}\\n\"\n",
    "                \"See https://lmstudio.ai/docs/basics/server for more information\"\n",
    "            )\n",
    "            exit(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_loop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize LM Studio client\n",
    "\n",
    "# client = OpenAI(base_url=\"http://127.0.0.1:1234/v1\", api_key=\"lm-studio\")\n",
    "# MODEL = \"meta-llama-3.1-8b-instruct\"\n",
    "\n",
    "\n",
    "# # Define tool for my local Agent\n",
    "# BIKE_TOOL = {\n",
    "#     \"type\": \"function\",\n",
    "#     \"function\": {\n",
    "#         \"name\": \"bike_availability_agent\",\n",
    "#         \"description\": (\n",
    "#             \"Retrouve le nombre de places et de vélos disponibles à un arrêt de vélo spécifique. \"\n",
    "#             \"Utilise toujours le nom d'arrêt demandé.\"\n",
    "#         ),\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"target_stop\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"Nom de l'arrêt à vérifier.\",\n",
    "#                 },\n",
    "#             },\n",
    "#             \"required\": [\"target_stop\"],\n",
    "#         },\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# messages=[\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"content\": (\n",
    "#             \"Tu es un assistant spécialisé dans la recherche d'informations sur les stations de vélos en libre-service. Tu ne réponds qu'à des questions sur les stations de vélos.\"\n",
    "#             \"Tu es très sérieux et professionnel. Tu ne t'éloignes jamais du sujet et tu ne fais pas de blagues.\"\n",
    "#             \"Ta mission est de fournir le nombre de places disponibles pour garer les vélos et le nombre de vélos disponibles à une station spécifique, en te basant sur une liste de stations. \"\n",
    "#             \"Tu es capable de reconnaître la station demandée par l'utilisateur, même si le nom comporte des fautes de frappe ou des variations.\"\n",
    "#             \"En te basant sur la liste des stations disponibles, tu proposes la station qui semble la mieux correspondre à la requête de l'utilisateur même si aucune correspondance exacte n'est trouvée.\"\n",
    "\n",
    "#             f\"Liste des stations disponibles : {stop_list} \"\n",
    "\n",
    "#             \"Réponds toujours dans le format suivant : 'Désolé, je n'ai pas trouvé d'informations sur la disponibilité des vélos à [nom de la station demandée]. Veuillez essayer une autre station. Cependant, j'ai pu trouver que l'une des stations les plus proches est \\\"[nom de la station trouvée]\\\" qui a [nombre] places pour garer vos vélos et [nombre] vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d'autres questions, n'hésitez pas à me poser!' \"\n",
    "#             \"Ne mentionne jamais la liste complète des stations à l'utilisateur. \"\n",
    "\n",
    "#             \"Exemples : \"\n",
    "#             \"Utilisateur : 'Je cherche des vélos à la gare de Lil.'\\nAssistant : 'Désolé, je n'ai pas trouvé d'informations sur la disponibilité des vélos à Gare de Lil. Cependant, j'ai pu trouver que l'une des stations les plus proches est \\\"Gare de Lille\\\" qui a xxx places pour garer vos vélos et xxx vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d'autres questions, n'hésitez pas à me questionner!'\\n\\n\"\n",
    "#             \"Utilisateur : 'Velo a Republique'\\nAssistant : 'Désolé, je n'ai pas trouvé d'informations sur la disponibilité des vélos à Republique. Cependant, j'ai pu trouver que l'une des stations les plus proches est \\\"République Beaux-Arts\\\" qui a xxx places pour garer vos vélos et xxx vélos disponibles pour emprunter. Si vous souhaitez savoir la disponibilité des autres stations ou si vous avez d'autres questions, n'hésitez pas à me questionner!'\\n\\n\"\n",
    "#         ),\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"Quelle est la recette pour faire un gâteau au chocolat ?\",\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# # Example usage of the tool\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     tools=[BIKE_TOOL],\n",
    "#     messages = messages,\n",
    "#     temperature=0.5\n",
    "# )\n",
    "\n",
    "# response_message = response.choices[0].message\n",
    "\n",
    "# tool_calls = response_message.tool_calls\n",
    "# if tool_calls:\n",
    "#     available_functions = {\n",
    "#         \"bike_availability_agent\": bike_availability_agent,\n",
    "#     }\n",
    "#     messages.append(response_message)\n",
    "#     for tool_call in tool_calls:\n",
    "#         function_name = tool_call.function.name\n",
    "#         function_to_call = available_functions[function_name]\n",
    "#         function_args = json.loads(tool_call.function.arguments)\n",
    "#         function_response = function_to_call(\n",
    "#             target_stop=function_args.get(\"target_stop\")\n",
    "#         )\n",
    "#         print(function_response)\n",
    "#         messages.append(\n",
    "#             {\n",
    "#                 \"tool_call_id\": tool_call.id,\n",
    "#                 \"role\": \"tool\",\n",
    "#                 \"name\": function_name,\n",
    "#                 \"content\": json.dumps(function_response),\n",
    "#             }\n",
    "#         )     \n",
    "#     second_response = client.chat.completions.create(\n",
    "#         model=MODEL,\n",
    "#         messages=messages\n",
    "#     )\n",
    "#     print(second_response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
